<<<<<<< HEAD
<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"analyse_predict_student_version-1529 (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k3iztl7u3gwD"},"source":["# Analyse - Predict\n","\n","Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions you will write all use Eskom data/variables.\n","\n","## Instructions to Students\n","- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n","- Answer the questions according to the specifications provided.\n","- Use the given cell in each question to to see if your function matches the expected outputs.\n","- Do not hard-code answers to the questions.\n","- The use of stackoverflow, google, and other online tools are permitted. However, copying fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%.\n","- Good luck, and may the force be with you!"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R538DUxtUirz"},"source":["## Imports"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"KDEvrdUcva3a"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SHBiOaLSUisC"},"source":["## Data Loading and Preprocessing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hY7BVNSkUisF"},"source":["### Electricification by province (EBP) data"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":1304,"status":"ok","timestamp":1582015286574,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"},"user_tz":-120},"id":"RxZaMCP6UisI","outputId":"848846bd-83f3-4997-d172-28c0a448e8c4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Financial Year (1 April - 30 March)</th>\n","      <th>Limpopo</th>\n","      <th>Mpumalanga</th>\n","      <th>North west</th>\n","      <th>Free State</th>\n","      <th>Kwazulu Natal</th>\n","      <th>Eastern Cape</th>\n","      <th>Western Cape</th>\n","      <th>Northern Cape</th>\n","      <th>Gauteng</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2000/1</td>\n","      <td>51860</td>\n","      <td>28365</td>\n","      <td>48429</td>\n","      <td>21293</td>\n","      <td>63413</td>\n","      <td>49008</td>\n","      <td>48429</td>\n","      <td>6168</td>\n","      <td>39660</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2001/2</td>\n","      <td>68121</td>\n","      <td>26303</td>\n","      <td>38685</td>\n","      <td>20928</td>\n","      <td>64123</td>\n","      <td>45773</td>\n","      <td>38685</td>\n","      <td>10359</td>\n","      <td>36024</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2002/3</td>\n","      <td>49881</td>\n","      <td>11976</td>\n","      <td>28532</td>\n","      <td>10316</td>\n","      <td>63078</td>\n","      <td>55748</td>\n","      <td>28532</td>\n","      <td>6869</td>\n","      <td>32127</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2003/4</td>\n","      <td>42034</td>\n","      <td>33515</td>\n","      <td>34027</td>\n","      <td>16135</td>\n","      <td>60282</td>\n","      <td>47414</td>\n","      <td>34027</td>\n","      <td>10976</td>\n","      <td>39488</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2004/5</td>\n","      <td>54646</td>\n","      <td>16218</td>\n","      <td>21450</td>\n","      <td>5668</td>\n","      <td>37811</td>\n","      <td>42041</td>\n","      <td>21450</td>\n","      <td>6316</td>\n","      <td>18422</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Financial Year (1 April - 30 March)  Limpopo  ...  Northern Cape  Gauteng\n","0                              2000/1    51860  ...           6168    39660\n","1                              2001/2    68121  ...          10359    36024\n","2                              2002/3    49881  ...           6869    32127\n","3                              2003/4    42034  ...          10976    39488\n","4                              2004/5    54646  ...           6316    18422\n","\n","[5 rows x 10 columns]"]},"execution_count":46,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["ebp_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/electrification_by_province.csv'\n","ebp_df = pd.read_csv(ebp_url)\n","\n","for col, row in ebp_df.iloc[:,1:].iteritems():\n","    ebp_df[col] = ebp_df[col].str.replace(',','').astype(int)\n","\n","ebp_df.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"221h1EhIUisV"},"source":["### Twitter data"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":1370,"status":"ok","timestamp":1582015289820,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"},"user_tz":-120},"id":"hhuJhhc0UisX","outputId":"5d597ca3-c165-404d-b366-9a359b879951"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Tweets                 Date\n","0  @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54\n","1         @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53\n","2       @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10\n","3  Before leaving the office this afternoon, head...  2019-11-29 12:33:36\n","4  #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43"]},"execution_count":47,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["twitter_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/twitter_nov_2019.csv'\n","twitter_df = pd.read_csv(twitter_url)\n","twitter_df.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eIO6A7GTUisg"},"source":["## Important Variables (Do not edit these!)"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"d4dKw4exUisi"},"outputs":[],"source":["# gauteng ebp data as a list\n","gauteng = ebp_df['Gauteng'].astype(float).to_list()\n","\n","# dates for twitter tweets\n","dates = twitter_df['Date'].to_list()\n","\n","# dictionary mapping official municipality twitter handles to the municipality name\n","mun_dict = {\n","    '@CityofCTAlerts' : 'Cape Town',\n","    '@CityPowerJhb' : 'Johannesburg',\n","    '@eThekwiniM' : 'eThekwini' ,\n","    '@EMMInfo' : 'Ekurhuleni',\n","    '@centlecutility' : 'Mangaung',\n","    '@NMBmunicipality' : 'Nelson Mandela Bay',\n","    '@CityTshwane' : 'Tshwane'\n","}\n","\n","# dictionary of english stopwords\n","stop_words_dict = {\n","    'stopwords':[\n","        'where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', \n","        'may', 'why', 'â€™s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', \n","        'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', \n","        'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', \n","        'their', 'various', 'thereafter', 'â€˜d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', \n","        'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', \n","        'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', 'â€™ve', 'might', 'see', 'whose', \n","        'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', \n","        'became', 'however', 'many', 'thence', 'onto', 'â€˜m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', \n","        'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', \n","        'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', \n","        'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', \n","        'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', \n","        'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', 'â€™d', 'under', \n","        'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', \n","        'nâ€™t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', \n","        'much', 'another', 'since', 'hundred', 'serious', 'â€˜ve', 'ever', 'out', 'full', 'themselves', \n","        'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \n","        \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', \n","        'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', 'â€™ll', 'latterly', 'are', 'ten', \n","        'hers', 'should', 'they', 'â€˜s', 'either', 'am', 'be', 'perhaps', 'â€™re', 'only', 'namely', 'sixty', \n","        'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', \n","        'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', 'â€˜ll', 'too', \n","        'seems', 'â€™m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', \n","        'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', \n","        'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', \n","        'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'nâ€˜t',\n","        'him', 'could', 'front', 'within', 'â€˜re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', \n","        'same', 'were', 'it', 'every', 'third', 'together'\n","    ]\n","}"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uLLfADfm3qAN"},"source":["## Function 1: Metric Dictionary\n","\n","Write a function that calculates the mean, median, variance, standard deviation, minimum and maximum of of list of items. You can assume the given list is contains only numerical entries, and you may use numpy functions to do this.\n","\n","**Function Specifications:**\n","- Function should allow a list as input.\n","- It should return a `dict` with keys `'mean'`, `'median'`, `'std'`, `'var'`, `'min'`, and `'max'`, corresponding to the mean, median, standard deviation, variance, minimum and maximum of the input list, respectively.\n","- The standard deviation and variance values must be unbiased. **Hint:** use the `ddof` parameter in the corresponding numpy functions!\n","- All values in the returned `dict` should be rounded to 2 decimal places."]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"wZft9kpnUism"},"outputs":[],"source":["### START FUNCTION\n","def dictionary_of_metrics(items):\n","    # your code here\n","    return\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"xJQoSiphUisr"},"outputs":[],"source":["dictionary_of_metrics(gauteng)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LWF1JOcu3wru"},"source":["_**Expected Output**_:\n","\n","```python\n","dictionary_of_metrics(gauteng) == {'mean': 26244.42,\n","                                   'median': 24403.5,\n","                                   'var': 108160153.17,\n","                                   'std': 10400.01,\n","                                   'min': 8842.0,\n","                                   'max': 39660.0}\n"," ```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wRxJtgMV3yty"},"source":["## Function 2: Five Number Summary\n","\n","Write a function which takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/).\n","\n","**Function Specifications:**\n","- The function should take a list as input.\n","- The function should return a `dict` with keys `'max'`, `'median'`, `'min'`, `'q1'`, and `'q3'` corresponding to the maximum, median, minimum, first quartile and third quartile, respectively. You may use numpy functions to aid in your calculations.\n","- All numerical values should be rounded to two decimal places."]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"oZI7v0q-Uis2"},"outputs":[],"source":["### START FUNCTION\n","def five_num_summary(items):\n","    # your code here\n","    return\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"ybM3OvvPDXdq"},"outputs":[],"source":["five_num_summary(gauteng)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rXwuo3ac34RQ"},"source":["_**Expected Output:**_\n","\n","```python\n","five_num_summary(gauteng) == {\n","    'max': 39660.0,\n","    'median': 24403.5,\n","    'min': 8842.0,\n","    'q1': 18653.0,\n","    'q3': 36372.0\n","}\n","\n","```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YE__20-4339e"},"source":["## Function 3: Date Parser\n","\n","The `dates` variable (created at the top of this notebook) is a list of dates represented as strings. The string contains the date in `'yyyy-mm-dd'` format, as well as the time in `hh:mm:ss` formamt. The first three entries in this variable are:\n","```python\n","dates[:3] == [\n","    '2019-11-29 12:50:54',\n","    '2019-11-29 12:46:53',\n","    '2019-11-29 12:46:10'\n","]\n","```\n","\n","Write a function that takes as input a list of these datetime strings and returns only the date in `'yyyy-mm-dd'` format.\n","\n","**Function Specifications:**\n","- The function should take a list of strings as input.\n","- Each string in the input list is formatted as `'yyyy-mm-dd hh:mm:ss'`.\n","- The function should return a list of strings where each element in the returned list contains only the date in the `'yyyy-mm-dd'` format."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["### START FUNCTION\n","def date_parser(dates):\n","\n","    \"\"\" Takes in a list of strings in datetime format (yyyy-mm-dd) and returns a list of strings containing only the date (yyyy-mm-dd) \"\"\"\n","\n","    new_format = []\n","\n","    for i in dates:\n","        x = i.split(' ')\n","        new_format.append(x[0])\n","\n","    return new_format\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"skZNu98NUite"},"outputs":[],"source":["date_parser(dates[:3])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NR2f64A24OOp"},"source":["_**Expected Output:**_\n","\n","```python\n","date_parser(dates[:3]) == ['2019-11-29', '2019-11-29', '2019-11-29']\n","date_parser(dates[-3:]) == ['2019-11-20', '2019-11-20', '2019-11-20']\n","```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jmhEu6VU4N8k"},"source":["## Function 4: Municipality & Hashtag Detector\n","\n","Write a function which takes in a pandas dataframe and returns a modified dataframe that includes two new columns that contain information about the municipality and hashtag of the tweet.\n","\n","**Function Specifications:**\n","* Function should take a pandas `dataframe` as input.\n","* Extract the municipality from a tweet using the `mun_dict` dictonary given below, and insert the result into a new column named `'municipality'` in the same dataframe.\n","* Use the entry `np.nan` when a municipality is not found.\n","* Extract a list of hashtags from a tweet into a new column named `'hashtags'` in the same dataframe.\n","* Use the entry `np.nan` when no hashtags are found.\n","\n","**Hint:** you will need to `mun_dict` variable defined at the top of this notebook.\n","\n","```"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"tEwUCB2LmbLS"},"outputs":[],"source":["### START FUNCTION\n","def extract_municipality_hashtags(df):\n","  mun = []\n","  tweets = []\n","  for tweet in df['Tweets'].iteritems():\n","    tweets.append(tweet[1].split(' '))\n","  for t in tweets:\n","    if '@' in word and word in mun_dict.keys():\n","      mun.append(mun_dict[word])\n","    else:\n","      mun.append(np.nan)\n","  df = df.assign(municipality = mun)\n","  return df\n","### END FUNCTION"]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"colab_type":"code","executionInfo":{"elapsed":1536,"status":"error","timestamp":1582021710201,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"},"user_tz":-120},"id":"WqkrrcqekMa2","outputId":"97fdb8d1-3d1d-4a4a-8b4e-69a962f10e8a"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-124-5903f4b07254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmun_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmun_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmunicipality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY36\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3669\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3670\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3671\u001b[0m             \u001b[0;31m# <= 3.5: do all calculations first...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3486\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3487\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of values does not match length of index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"]}],"source":["df  = twitter_df.copy()\n","mun = []\n","tweets = []\n","for tweet in df['Tweets'].iteritems():\n","  tweets.append(tweet[1].split(' '))\n","for t in tweets:\n","  for word in t:\n","    if word in mun_dict.keys():\n","      mun.append(mun_dict[word])\n","df = df.assign(municipality = mun)\n","df.head(30)"]},{"cell_type":"code","execution_count":116,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"colab_type":"code","executionInfo":{"elapsed":1242,"status":"ok","timestamp":1582020300392,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"},"user_tz":-120},"id":"xgb0KGnQUit6","outputId":"8b41035b-2ec2-4bad-f3d1-9bf4c1cb4a53"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","      <th>municipality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Eskom's Visitors Centres’ facilities include i...</td>\n","      <td>2019-11-20 10:29:07</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>#Eskom connected 400 houses and in the process...</td>\n","      <td>2019-11-20 10:25:20</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>@ArthurGodbeer Is the power restored as yet?</td>\n","      <td>2019-11-20 10:07:59</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n","      <td>2019-11-20 10:07:41</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n","      <td>2019-11-20 10:00:09</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                Tweets  ... municipality\n","0    @BongaDlulane Please send an email to mediades...  ...          NaN\n","1           @saucy_mamiie Pls log a call on 0860037566  ...          NaN\n","2         @BongaDlulane Query escalated to media desk.  ...          NaN\n","3    Before leaving the office this afternoon, head...  ...          NaN\n","4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  ...          NaN\n","..                                                 ...  ...          ...\n","195  Eskom's Visitors Centres’ facilities include i...  ...          NaN\n","196  #Eskom connected 400 houses and in the process...  ...          NaN\n","197       @ArthurGodbeer Is the power restored as yet?  ...          NaN\n","198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  ...          NaN\n","199  RT @GP_DHS: The @GautengProvince made a commit...  ...          NaN\n","\n","[200 rows x 3 columns]"]},"execution_count":116,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["extract_municipality_hashtags(twitter_df.copy())"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RO39F02A4qEp"},"source":["_**Expected Outputs:**_ \n","\n","```python\n","\n","extract_municipality_hashtags(twitter_df.copy())\n","\n","```\n","> <table class=\"dataframe\" border=\"1\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","      <th>municipality</th>\n","      <th>hashtags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","      <td>NaN</td>\n","      <td>[#eskomfreestate, #mediastatement]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n","      <td>2019-11-20 10:29:07</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>#Eskom connected 400 houses and in the process...</td>\n","      <td>2019-11-20 10:25:20</td>\n","      <td>NaN</td>\n","      <td>[#eskom, #eskom, #poweringyourworld]</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>@ArthurGodbeer Is the power restored as yet?</td>\n","      <td>2019-11-20 10:07:59</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n","      <td>2019-11-20 10:07:41</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n","      <td>2019-11-20 10:00:09</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zL2f74Iv4vF4"},"source":["## Function 5: Number of Tweets per Day\n","\n","Write a function which calculates the number of tweets that were posted per day. \n","\n","**Function Specifications:**\n","- It should take a pandas dataframe as input.\n","- It should return a new dataframe, grouped by day, with the number of tweets for that day.\n","- The index of the new dataframe should be named `Date`, and the column of the new dataframe should be `'Tweets'`, corresponding to the date and number of tweets, respectively.\n","- The date should be formated as `yyyy-mm-dd`, and should be a datetime object. **Hint:** look up `pd.to_datetime` to see how to do this."]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"2OgGwo22vogg"},"outputs":[],"source":["### START FUNCTION\n","def number_of_tweets_per_day(df):\n","    # your code here\n","    return\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"lDp1Wa7kUiuX"},"outputs":[],"source":["number_of_tweets_per_day(twitter_df.copy())"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sRgKYS5r41CY"},"source":["_**Expected Output:**_\n","\n","```python\n","\n","number_of_tweets_per_day(twitter_df.copy())\n","\n","```\n","\n","> <table class=\"dataframe\" border=\"1\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2019-11-20</th>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-21</th>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-22</th>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-23</th>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-24</th>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-25</th>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-26</th>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-27</th>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-28</th>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2019-11-29</th>\n","      <td>16</td>\n","    </tr>\n","  </tbody>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BbDANpgZ46qz"},"source":["# Function 6: Word Splitter\n","\n","Write a function which splits the sentences in a dataframe's column into a list of the separate words. The created lists should be placed in a column named `'Split Tweets'` in the original dataframe. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n","\n","**Function Specifications:**\n","- It should take a pandas dataframe as an input.\n","- The dataframe should contain a column, named `'Tweets'`.\n","- The function should split the sentences in the `'Tweets'` into a list of seperate words, and place the result into a new column named `'Split Tweets'`. The resulting words must all be lowercase!\n","- The function should modify the input dataframe directly.\n","- The function should return the modified dataframe."]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"EYWIHnwy7_0A"},"outputs":[],"source":["### START FUNCTION\n","def word_splitter(df):\n","    split_tweets = []\n","    for tweet in df['Tweets'].iteritems():\n","      split_tweets.append(tweet[1].split(' '))\n","    split_tweets = [[word.lower() for word in tweet] for tweet in split_tweets]\n","    df = df.assign(Split_Tweets = split_tweets).rename(columns={'Split_Tweets': 'Split Tweets'})\n","    return df\n","### END FUNCTION"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"colab_type":"code","executionInfo":{"elapsed":938,"status":"ok","timestamp":1582016806740,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"},"user_tz":-120},"id":"VNvFPqbVUivO","outputId":"6ee8bb1d-144c-4e6d-c67a-79e9d57ddcf5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","      <th>Split Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","      <td>[@bongadlulane, please, send, an, email, to, m...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","      <td>[@saucy_mamiie, pls, log, a, call, on, 0860037...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","      <td>[@bongadlulane, query, escalated, to, media, d...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","      <td>[before, leaving, the, office, this, afternoon...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Eskom's Visitors Centres’ facilities include i...</td>\n","      <td>2019-11-20 10:29:07</td>\n","      <td>[eskom's, visitors, centres’, facilities, incl...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>#Eskom connected 400 houses and in the process...</td>\n","      <td>2019-11-20 10:25:20</td>\n","      <td>[#eskom, connected, 400, houses, and, in, the,...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>@ArthurGodbeer Is the power restored as yet?</td>\n","      <td>2019-11-20 10:07:59</td>\n","      <td>[@arthurgodbeer, is, the, power, restored, as,...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n","      <td>2019-11-20 10:07:41</td>\n","      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n","      <td>2019-11-20 10:00:09</td>\n","      <td>[rt, @gp_dhs:, the, @gautengprovince, made, a,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>200 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                Tweets  ...                                       Split Tweets\n","0    @BongaDlulane Please send an email to mediades...  ...  [@bongadlulane, please, send, an, email, to, m...\n","1           @saucy_mamiie Pls log a call on 0860037566  ...  [@saucy_mamiie, pls, log, a, call, on, 0860037...\n","2         @BongaDlulane Query escalated to media desk.  ...  [@bongadlulane, query, escalated, to, media, d...\n","3    Before leaving the office this afternoon, head...  ...  [before, leaving, the, office, this, afternoon...\n","4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  ...  [#eskomfreestate, #mediastatement, :, eskom, s...\n","..                                                 ...  ...                                                ...\n","195  Eskom's Visitors Centres’ facilities include i...  ...  [eskom's, visitors, centres’, facilities, incl...\n","196  #Eskom connected 400 houses and in the process...  ...  [#eskom, connected, 400, houses, and, in, the,...\n","197       @ArthurGodbeer Is the power restored as yet?  ...  [@arthurgodbeer, is, the, power, restored, as,...\n","198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  ...  [@muthambipaulina, @sabcnewsonline, @iol, @enc...\n","199  RT @GP_DHS: The @GautengProvince made a commit...  ...  [rt, @gp_dhs:, the, @gautengprovince, made, a,...\n","\n","[200 rows x 3 columns]"]},"execution_count":93,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["word_splitter(twitter_df.copy())"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_QtthCC44_6p"},"source":["_**Expected Output**_:\n","\n","```python\n","\n","word_splitter(twitter_df.copy()) \n","\n","```\n","\n","> <table class=\"dataframe\" border=\"1\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","      <th>Split Tweets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","      <td>[@bongadlulane, please, send, an, email, to, m...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","      <td>[@saucy_mamiie, pls, log, a, call, on, 0860037...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","      <td>[@bongadlulane, query, escalated, to, media, d...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","      <td>[before, leaving, the, office, this, afternoon...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n","      <td>2019-11-20 10:29:07</td>\n","      <td>[eskom's, visitors, centresâ€™, facilities, incl...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>#Eskom connected 400 houses and in the process...</td>\n","      <td>2019-11-20 10:25:20</td>\n","      <td>[#eskom, connected, 400, houses, and, in, the,...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>@ArthurGodbeer Is the power restored as yet?</td>\n","      <td>2019-11-20 10:07:59</td>\n","      <td>[@arthurgodbeer, is, the, power, restored, as,...</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n","      <td>2019-11-20 10:07:41</td>\n","      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n","      <td>2019-11-20 10:00:09</td>\n","      <td>[rt, @gp_dhs:, the, @gautengprovince, made, a,...</td>\n","    </tr>\n","  </tbody>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r-L3kWZh5DvM"},"source":["# Function 7: Stop Words\n","\n","Write a function which removes english stop words from a tweet.\n","\n","**Function Specifications:**\n","- It should take a pandas dataframe as input.\n","- Should tokenise the sentences according to the definition in function 6. Note that function 6 **cannot be called within this function**.\n","- Should remove all stop words in the tokenised list. The stopwords are defined in the `stop_words_dict` variable defined at the top of this notebook.\n","- The resulting tokenised list should be placed in a column named `\"Without Stop Words\"`.\n","- The function should modify the input dataframe.\n","- The function should return the modified dataframe.\n"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"qCZnUoU64mVj"},"outputs":[],"source":["### START FUNCTION\n","def stop_words_remover(df):\n","    # your code here\n","    return\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"TYMysrQUUivq"},"outputs":[],"source":["stop_words_remover(twitter_df.copy())"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DGzO-tYv5O0N"},"source":["_**Expected Output**_:\n","\n","Specific rows:\n","\n","```python\n","stop_words_remover(twitter_df.copy()).loc[0, \"Without Stop Words\"] == ['@bongadlulane', 'send', 'email', 'mediadesk@eskom.co.za']\n","stop_words_remover(twitter_df.copy()).loc[100, \"Without Stop Words\"] == ['#eskomnorthwest', '#mediastatement', ':', 'notice', 'supply', 'interruption', 'lichtenburg', 'area', 'https://t.co/7hfwvxllit']\n","```\n","\n","Whole table:\n","```python\n","stop_words_remover(twitter_df.copy())\n","```\n","\n","> <table class=\"dataframe\" border=\"1\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Tweets</th>\n","      <th>Date</th>\n","      <th>Without Stop Words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@BongaDlulane Please send an email to mediades...</td>\n","      <td>2019-11-29 12:50:54</td>\n","      <td>[@bongadlulane, send, email, mediadesk@eskom.c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n","      <td>2019-11-29 12:46:53</td>\n","      <td>[@saucy_mamiie, pls, log, 0860037566]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@BongaDlulane Query escalated to media desk.</td>\n","      <td>2019-11-29 12:46:10</td>\n","      <td>[@bongadlulane, query, escalated, media, desk.]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Before leaving the office this afternoon, head...</td>\n","      <td>2019-11-29 12:33:36</td>\n","      <td>[leaving, office, afternoon,, heading, weekend...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n","      <td>2019-11-29 12:17:43</td>\n","      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n","      <td>2019-11-20 10:29:07</td>\n","      <td>[eskom's, visitors, centresâ€™, facilities, incl...</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>#Eskom connected 400 houses and in the process...</td>\n","      <td>2019-11-20 10:25:20</td>\n","      <td>[#eskom, connected, 400, houses, process, conn...</td>\n","    </tr>\n","    <tr>\n","      <th>197</th>\n","      <td>@ArthurGodbeer Is the power restored as yet?</td>\n","      <td>2019-11-20 10:07:59</td>\n","      <td>[@arthurgodbeer, power, restored, yet?]</td>\n","    </tr>\n","    <tr>\n","      <th>198</th>\n","      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n","      <td>2019-11-20 10:07:41</td>\n","      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n","      <td>2019-11-20 10:00:09</td>\n","      <td>[rt, @gp_dhs:, @gautengprovince, commitment, e...</td>\n","    </tr>\n","  </tbody>\n","</table>"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"9od8CQ8wUivu"},"outputs":[],"source":[""]}]}
=======
=======
>>>>>>> upstream/master
{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "k3iztl7u3gwD"
   },
   "outputs": [],
   "source": [
    "# Analyse - Predict\n",
    "\n",
    "Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions you will write all use Eskom data/variables.\n",
    "\n",
    "## Instructions to Students\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "- Answer the questions according to the specifications provided.\n",
    "- Use the given cell in each question to to see if your function matches the expected outputs.\n",
    "- Do not hard-code answers to the questions.\n",
    "- The use of stackoverflow, google, and other online tools are permitted. However, copying fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%.\n",
    "- Good luck, and may the force be with you!"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "R538DUxtUirz"
   },
   "outputs": [],
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "SHBiOaLSUisC"
   },
   "outputs": [],
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "hY7BVNSkUisF"
   },
   "outputs": [],
   "source": [
    "### Electricification by province (EBP) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Financial Year (1 April - 30 March)</th>\n      <th>Limpopo</th>\n      <th>Mpumalanga</th>\n      <th>North west</th>\n      <th>Free State</th>\n      <th>Kwazulu Natal</th>\n      <th>Eastern Cape</th>\n      <th>Western Cape</th>\n      <th>Northern Cape</th>\n      <th>Gauteng</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2000/1</td>\n      <td>51860</td>\n      <td>28365</td>\n      <td>48429</td>\n      <td>21293</td>\n      <td>63413</td>\n      <td>49008</td>\n      <td>48429</td>\n      <td>6168</td>\n      <td>39660</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2001/2</td>\n      <td>68121</td>\n      <td>26303</td>\n      <td>38685</td>\n      <td>20928</td>\n      <td>64123</td>\n      <td>45773</td>\n      <td>38685</td>\n      <td>10359</td>\n      <td>36024</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2002/3</td>\n      <td>49881</td>\n      <td>11976</td>\n      <td>28532</td>\n      <td>10316</td>\n      <td>63078</td>\n      <td>55748</td>\n      <td>28532</td>\n      <td>6869</td>\n      <td>32127</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2003/4</td>\n      <td>42034</td>\n      <td>33515</td>\n      <td>34027</td>\n      <td>16135</td>\n      <td>60282</td>\n      <td>47414</td>\n      <td>34027</td>\n      <td>10976</td>\n      <td>39488</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2004/5</td>\n      <td>54646</td>\n      <td>16218</td>\n      <td>21450</td>\n      <td>5668</td>\n      <td>37811</td>\n      <td>42041</td>\n      <td>21450</td>\n      <td>6316</td>\n      <td>18422</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Financial Year (1 April - 30 March)  Limpopo  Mpumalanga  North west  \\\n0                              2000/1    51860       28365       48429   \n1                              2001/2    68121       26303       38685   \n2                              2002/3    49881       11976       28532   \n3                              2003/4    42034       33515       34027   \n4                              2004/5    54646       16218       21450   \n\n   Free State  Kwazulu Natal  Eastern Cape  Western Cape  Northern Cape  \\\n0       21293          63413         49008         48429           6168   \n1       20928          64123         45773         38685          10359   \n2       10316          63078         55748         28532           6869   \n3       16135          60282         47414         34027          10976   \n4        5668          37811         42041         21450           6316   \n\n   Gauteng  \n0    39660  \n1    36024  \n2    32127  \n3    39488  \n4    18422  "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebp_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/electrification_by_province.csv'\n",
    "ebp_df = pd.read_csv(ebp_url)\n",
    "\n",
    "for col, row in ebp_df.iloc[:,1:].iteritems():\n",
    "    ebp_df[col] = ebp_df[col].str.replace(',','').astype(int)\n",
    "\n",
    "ebp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "221h1EhIUisV"
   },
   "outputs": [],
   "source": [
    "### Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              Tweets                 Date\n0  @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54\n1         @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53\n2       @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10\n3  Before leaving the office this afternoon, head...  2019-11-29 12:33:36\n4  #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_url = 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/twitter_nov_2019.csv'\n",
    "twitter_df = pd.read_csv(twitter_url)\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "eIO6A7GTUisg"
   },
   "outputs": [],
   "source": [
    "## Important Variables (Do not edit these!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gauteng ebp data as a list\n",
    "gauteng = ebp_df['Gauteng'].astype(float).to_list()\n",
    "\n",
    "# dates for twitter tweets\n",
    "dates = twitter_df['Date'].to_list()\n",
    "\n",
    "# dictionary mapping official municipality twitter handles to the municipality name\n",
    "mun_dict = {\n",
    "    '@CityofCTAlerts' : 'Cape Town',\n",
    "    '@CityPowerJhb' : 'Johannesburg',\n",
    "    '@eThekwiniM' : 'eThekwini' ,\n",
    "    '@EMMInfo' : 'Ekurhuleni',\n",
    "    '@centlecutility' : 'Mangaung',\n",
    "    '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "    '@CityTshwane' : 'Tshwane'\n",
    "}\n",
    "\n",
    "# dictionary of english stopwords\n",
    "stop_words_dict = {\n",
    "    'stopwords':[\n",
    "        'where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', \n",
    "        'may', 'why', 'â€™s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', \n",
    "        'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', \n",
    "        'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', \n",
    "        'their', 'various', 'thereafter', 'â€˜d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', \n",
    "        'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', \n",
    "        'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', 'â€™ve', 'might', 'see', 'whose', \n",
    "        'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', \n",
    "        'became', 'however', 'many', 'thence', 'onto', 'â€˜m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', \n",
    "        'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', \n",
    "        'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', \n",
    "        'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', \n",
    "        'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', \n",
    "        'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', 'â€™d', 'under', \n",
    "        'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', \n",
    "        'nâ€™t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', \n",
    "        'much', 'another', 'since', 'hundred', 'serious', 'â€˜ve', 'ever', 'out', 'full', 'themselves', \n",
    "        'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \n",
    "        \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', \n",
    "        'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', 'â€™ll', 'latterly', 'are', 'ten', \n",
    "        'hers', 'should', 'they', 'â€˜s', 'either', 'am', 'be', 'perhaps', 'â€™re', 'only', 'namely', 'sixty', \n",
    "        'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', \n",
    "        'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', 'â€˜ll', 'too', \n",
    "        'seems', 'â€™m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', \n",
    "        'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', \n",
    "        'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', \n",
    "        'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'nâ€˜t',\n",
    "        'him', 'could', 'front', 'within', 'â€˜re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', \n",
    "        'same', 'were', 'it', 'every', 'third', 'together'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "uLLfADfm3qAN"
   },
   "outputs": [],
   "source": [
    "## Function 1: Metric Dictionary\n",
    "\n",
    "Write a function that calculates the mean, median, variance, standard deviation, minimum and maximum of of list of items. You can assume the given list is contains only numerical entries, and you may use numpy functions to do this.\n",
    "\n",
    "**Function Specifications:**\n",
    "- Function should allow a list as input.\n",
    "- It should return a `dict` with keys `'mean'`, `'median'`, `'std'`, `'var'`, `'min'`, and `'max'`, corresponding to the mean, median, standard deviation, variance, minimum and maximum of the input list, respectively.\n",
    "- The standard deviation and variance values must be unbiased. **Hint:** use the `ddof` parameter in the corresponding numpy functions!\n",
    "- All values in the returned `dict` should be rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def dictionary_of_metrics(items):\n",
    "    n = len(items)\n",
    "    items = sorted(items)\n",
    "    \n",
    "    #mean calculations\n",
    "    sum1 = sum(items)\n",
    "    mean = round(sum1/n,2)\n",
    "    \n",
    "    # median calculation\n",
    "    if n % 2 == 0: \n",
    "        med= items[n//2] \n",
    "        med2= items[n//2 - 1] \n",
    "        median = round((med + med2)/2, 2)\n",
    "    else: \n",
    "        median = round(items[n//2], 2) \n",
    "    \n",
    "    #varience calculations\n",
    "    #for i in items:\n",
    "    #varience = round(mean -(items[i]**2))\n",
    "    varience = round(np.var(items, ddof=1), 2)\n",
    "    \n",
    "    #standard deviation\n",
    "    std = round(np.std(items, ddof=1), 2)\n",
    "    #maximum number\n",
    "    max1 =round(max(items), 2)\n",
    "    #minimum number\n",
    "    min1 = round(min(items), 2)\n",
    "    \n",
    "    return {'mean':mean,'median': median,'var': varience,'std':std, 'min':min1, 'max':max1}\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean': 26244.42,\n 'median': 24403.5,\n 'var': 108160153.17,\n 'std': 10400.01,\n 'min': 8842.0,\n 'max': 39660.0}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_of_metrics(gauteng)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "LWF1JOcu3wru"
   },
   "outputs": [],
   "source": [
    "_**Expected Output**_:\n",
    "\n",
    "```python\n",
    "dictionary_of_metrics(gauteng) == {'mean': 26244.42,\n",
    "                                   'median': 24403.5,\n",
    "                                   'var': 108160153.17,\n",
    "                                   'std': 10400.01,\n",
    "                                   'min': 8842.0,\n",
    "                                   'max': 39660.0}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "wRxJtgMV3yty"
   },
   "outputs": [],
   "source": [
    "## Function 2: Five Number Summary\n",
    "\n",
    "Write a function which takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/).\n",
    "\n",
    "**Function Specifications:**\n",
    "- The function should take a list as input.\n",
    "- The function should return a `dict` with keys `'max'`, `'median'`, `'min'`, `'q1'`, and `'q3'` corresponding to the maximum, median, minimum, first quartile and third quartile, respectively. You may use numpy functions to aid in your calculations.\n",
    "- All numerical values should be rounded to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def five_num_summ(items):\n",
    "\n",
    "    ord_items = sorted(items)\n",
    "    minimum = min(ord_items)\n",
    "    maximum = max(ord_items)\n",
    "\n",
    "    #=====Calculating Median=====#\n",
    "    def quartile(n_percentile):\n",
    "        percentile = len(ord_items) * (n_percentile/100)\n",
    "        if percentile == int(percentile):\n",
    "              return round((ord_items[int(percentile)-1]+ord_items[int(percentile)])/2,2)\n",
    "        else:\n",
    "              return round(ord_items[int(percentile)],2)\n",
    "\n",
    "     \n",
    "\n",
    "     ## calculate q1 using numpy.percentile\n",
    "    q1 = round(np.percentile(items, 25), 2)  \n",
    "\n",
    "     ## calculate q3 using numpy.percentile\n",
    "    q3 = round(np.percentile(items, 75), 2)\n",
    "  \n",
    "    dictionary = {'max':maximum, 'median':quartile(50), 'min':minimum, 'q1':q1, 'q3':q3}\n",
    "  \n",
    "    return dictionary\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'max': 39660.0,\n 'median': 24403.5,\n 'min': 8842.0,\n 'q1': 18653.0,\n 'q3': 36372.0}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_num_summ(gauteng)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "rXwuo3ac34RQ"
   },
   "outputs": [],
   "source": [
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "five_num_summary(gauteng) == {\n",
    "    'max': 39660.0,\n",
    "    'median': 24403.5,\n",
    "    'min': 8842.0,\n",
    "    'q1': 18653.0,\n",
    "    'q3': 36372.0\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "YE__20-4339e"
   },
   "outputs": [],
   "source": [
    "## Function 3: Date Parser\n",
    "\n",
    "The `dates` variable (created at the top of this notebook) is a list of dates represented as strings. The string contains the date in `'yyyy-mm-dd'` format, as well as the time in `hh:mm:ss` formamt. The first three entries in this variable are:\n",
    "```python\n",
    "dates[:3] == [\n",
    "    '2019-11-29 12:50:54',\n",
    "    '2019-11-29 12:46:53',\n",
    "    '2019-11-29 12:46:10'\n",
    "]\n",
    "```\n",
    "\n",
    "Write a function that takes as input a list of these datetime strings and returns only the date in `'yyyy-mm-dd'` format.\n",
    "\n",
    "**Function Specifications:**\n",
    "- The function should take a list of strings as input.\n",
    "- Each string in the input list is formatted as `'yyyy-mm-dd hh:mm:ss'`.\n",
    "- The function should return a list of strings where each element in the returned list contains only the date in the `'yyyy-mm-dd'` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def date_parser(dates):\n",
    "    # your code here\n",
    "    return\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_parser(dates[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "NR2f64A24OOp"
   },
   "outputs": [],
   "source": [
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "date_parser(dates[:3]) == ['2019-11-29', '2019-11-29', '2019-11-29']\n",
    "date_parser(dates[-3:]) == ['2019-11-20', '2019-11-20', '2019-11-20']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "jmhEu6VU4N8k"
   },
   "outputs": [],
   "source": [
    "## Function 4: Municipality & Hashtag Detector\n",
    "\n",
    "Write a function which takes in a pandas dataframe and returns a modified dataframe that includes two new columns that contain information about the municipality and hashtag of the tweet.\n",
    "\n",
    "**Function Specifications:**\n",
    "* Function should take a pandas `dataframe` as input.\n",
    "* Extract the municipality from a tweet using the `mun_dict` dictonary given below, and insert the result into a new column named `'municipality'` in the same dataframe.\n",
    "* Use the entry `np.nan` when a municipality is not found.\n",
    "* Extract a list of hashtags from a tweet into a new column named `'hashtags'` in the same dataframe.\n",
    "* Use the entry `np.nan` when no hashtags are found.\n",
    "\n",
    "**Hint:** you will need to `mun_dict` variable defined at the top of this notebook.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def extract_municipality_hashtags(df):\n",
    "  mun = []\n",
    "  tweets = []\n",
    "  for tweet in df['Tweets'].iteritems():\n",
    "    tweets.append(tweet[1].split(' '))\n",
    "  for t in tweets:\n",
    "    if '@' in word and word in mun_dict.keys():\n",
    "      mun.append(mun_dict[word])\n",
    "    else:\n",
    "      mun.append(np.nan)\n",
    "  df = df.assign(municipality = mun)\n",
    "  return df\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-ebd124f76990>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mextract_municipality_hashtags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwitter_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-a8691bef3090>\u001b[0m in \u001b[0;36mextract_municipality_hashtags\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;34m'@'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmun_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m       \u001b[0mmun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmun_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word' is not defined"
     ]
    }
   ],
   "source": [
    "extract_municipality_hashtags(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "RO39F02A4qEp"
   },
   "outputs": [],
   "source": [
    "_**Expected Outputs:**_ \n",
    "\n",
    "```python\n",
    "\n",
    "extract_municipality_hashtags(twitter_df.copy())\n",
    "\n",
    "```\n",
    "> <table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Tweets</th>\n",
    "      <th>Date</th>\n",
    "      <th>municipality</th>\n",
    "      <th>hashtags</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>@BongaDlulane Please send an email to mediades...</td>\n",
    "      <td>2019-11-29 12:50:54</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n",
    "      <td>2019-11-29 12:46:53</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>@BongaDlulane Query escalated to media desk.</td>\n",
    "      <td>2019-11-29 12:46:10</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>Before leaving the office this afternoon, head...</td>\n",
    "      <td>2019-11-29 12:33:36</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n",
    "      <td>2019-11-29 12:17:43</td>\n",
    "      <td>NaN</td>\n",
    "      <td>[#eskomfreestate, #mediastatement]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>195</th>\n",
    "      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n",
    "      <td>2019-11-20 10:29:07</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>196</th>\n",
    "      <td>#Eskom connected 400 houses and in the process...</td>\n",
    "      <td>2019-11-20 10:25:20</td>\n",
    "      <td>NaN</td>\n",
    "      <td>[#eskom, #eskom, #poweringyourworld]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>197</th>\n",
    "      <td>@ArthurGodbeer Is the power restored as yet?</td>\n",
    "      <td>2019-11-20 10:07:59</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>198</th>\n",
    "      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n",
    "      <td>2019-11-20 10:07:41</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>199</th>\n",
    "      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n",
    "      <td>2019-11-20 10:00:09</td>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "zL2f74Iv4vF4"
   },
   "outputs": [],
   "source": [
    "## Function 5: Number of Tweets per Day\n",
    "\n",
    "Write a function which calculates the number of tweets that were posted per day. \n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as input.\n",
    "- It should return a new dataframe, grouped by day, with the number of tweets for that day.\n",
    "- The index of the new dataframe should be named `Date`, and the column of the new dataframe should be `'Tweets'`, corresponding to the date and number of tweets, respectively.\n",
    "- The date should be formated as `yyyy-mm-dd`, and should be a datetime object. **Hint:** look up `pd.to_datetime` to see how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def number_of_tweets_per_day(df):\n",
    "    # your code here\n",
    "    return\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tweets_per_day(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "sRgKYS5r41CY"
   },
   "outputs": [],
   "source": [
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "\n",
    "number_of_tweets_per_day(twitter_df.copy())\n",
    "\n",
    "```\n",
    "\n",
    "> <table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Tweets</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Date</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>2019-11-20</th>\n",
    "      <td>18</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-21</th>\n",
    "      <td>11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-22</th>\n",
    "      <td>25</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-23</th>\n",
    "      <td>19</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-24</th>\n",
    "      <td>14</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-25</th>\n",
    "      <td>20</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-26</th>\n",
    "      <td>32</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-27</th>\n",
    "      <td>13</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-28</th>\n",
    "      <td>32</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2019-11-29</th>\n",
    "      <td>16</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "BbDANpgZ46qz"
   },
   "outputs": [],
   "source": [
    "# Function 6: Word Splitter\n",
    "\n",
    "Write a function which splits the sentences in a dataframe's column into a list of the separate words. The created lists should be placed in a column named `'Split Tweets'` in the original dataframe. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as an input.\n",
    "- The dataframe should contain a column, named `'Tweets'`.\n",
    "- The function should split the sentences in the `'Tweets'` into a list of seperate words, and place the result into a new column named `'Split Tweets'`. The resulting words must all be lowercase!\n",
    "- The function should modify the input dataframe directly.\n",
    "- The function should return the modified dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def word_splitter(df):\n",
    "    \"\"\" A function which splits the sentences in a dataframe's column into a list of the        separate words.\n",
    "    \"\"\"\n",
    "    # Create an empty list of tweets\n",
    "    split_tweets = []\n",
    "    # Iterate through the Tweets column on the dataframe\n",
    "    for tweet in df['Tweets'].iteritems():\n",
    "      # Split each tweet to lists of single words and append to split tweets\n",
    "      split_tweets.append(tweet[1].split(' '))\n",
    "    # Transform every letter on the tweets to lowercase\n",
    "    split_tweets = [[word.lower() for word in tweet] for tweet in split_tweets]\n",
    "    # Add a Split Tweets column to the dataframe\n",
    "    df = df.assign(Split_Tweets = split_tweets).rename(columns={'Split_Tweets': 'Split Tweets'})\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_splitter(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "_QtthCC44_6p"
   },
   "outputs": [],
   "source": [
    "_**Expected Output**_:\n",
    "\n",
    "```python\n",
    "\n",
    "word_splitter(twitter_df.copy()) \n",
    "\n",
    "```\n",
    "\n",
    "> <table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Tweets</th>\n",
    "      <th>Date</th>\n",
    "      <th>Split Tweets</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>@BongaDlulane Please send an email to mediades...</td>\n",
    "      <td>2019-11-29 12:50:54</td>\n",
    "      <td>[@bongadlulane, please, send, an, email, to, m...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n",
    "      <td>2019-11-29 12:46:53</td>\n",
    "      <td>[@saucy_mamiie, pls, log, a, call, on, 0860037...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>@BongaDlulane Query escalated to media desk.</td>\n",
    "      <td>2019-11-29 12:46:10</td>\n",
    "      <td>[@bongadlulane, query, escalated, to, media, d...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>Before leaving the office this afternoon, head...</td>\n",
    "      <td>2019-11-29 12:33:36</td>\n",
    "      <td>[before, leaving, the, office, this, afternoon...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n",
    "      <td>2019-11-29 12:17:43</td>\n",
    "      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>195</th>\n",
    "      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n",
    "      <td>2019-11-20 10:29:07</td>\n",
    "      <td>[eskom's, visitors, centresâ€™, facilities, incl...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>196</th>\n",
    "      <td>#Eskom connected 400 houses and in the process...</td>\n",
    "      <td>2019-11-20 10:25:20</td>\n",
    "      <td>[#eskom, connected, 400, houses, and, in, the,...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>197</th>\n",
    "      <td>@ArthurGodbeer Is the power restored as yet?</td>\n",
    "      <td>2019-11-20 10:07:59</td>\n",
    "      <td>[@arthurgodbeer, is, the, power, restored, as,...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>198</th>\n",
    "      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n",
    "      <td>2019-11-20 10:07:41</td>\n",
    "      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>199</th>\n",
    "      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n",
    "      <td>2019-11-20 10:00:09</td>\n",
    "      <td>[rt, @gp_dhs:, the, @gautengprovince, made, a,...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "r-L3kWZh5DvM"
   },
   "outputs": [],
   "source": [
    "# Function 7: Stop Words\n",
    "\n",
    "Write a function which removes english stop words from a tweet.\n",
    "\n",
    "**Function Specifications:**\n",
    "- It should take a pandas dataframe as input.\n",
    "- Should tokenise the sentences according to the definition in function 6. Note that function 6 **cannot be called within this function**.\n",
    "- Should remove all stop words in the tokenised list. The stopwords are defined in the `stop_words_dict` variable defined at the top of this notebook.\n",
    "- The resulting tokenised list should be placed in a column named `\"Without Stop Words\"`.\n",
    "- The function should modify the input dataframe.\n",
    "- The function should return the modified dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def stop_words_remover(df):\n",
    "    # your code here\n",
    "    \n",
    "    #Creating lambda function by joining the loop of lowercase list of string and remove the 'stopwords'\n",
    "    lambda_f = lambda x: ' '.join([item for item in x.lower().split() if item not in stop_words_dict['stopwords']])\n",
    "    \n",
    "    #Applying the lambda function to the dataframe and name new column as \"Without Stop Words\"\n",
    "    df['Without Stop Words'] = df[\"Tweets\"].apply(lambda_f)\n",
    "    \n",
    "    #Split the list of string in a new column\n",
    "    df['Without Stop Words'] = df['Without Stop Words'].str.split()\n",
    "    return df\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_remover(twitter_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "DGzO-tYv5O0N"
   },
   "outputs": [],
   "source": [
    "_**Expected Output**_:\n",
    "\n",
    "Specific rows:\n",
    "\n",
    "```python\n",
    "stop_words_remover(twitter_df.copy()).loc[0, \"Without Stop Words\"] == ['@bongadlulane', 'send', 'email', 'mediadesk@eskom.co.za']\n",
    "stop_words_remover(twitter_df.copy()).loc[100, \"Without Stop Words\"] == ['#eskomnorthwest', '#mediastatement', ':', 'notice', 'supply', 'interruption', 'lichtenburg', 'area', 'https://t.co/7hfwvxllit']\n",
    "```\n",
    "\n",
    "Whole table:\n",
    "```python\n",
    "stop_words_remover(twitter_df.copy())\n",
    "```\n",
    "\n",
    "> <table class=\"dataframe\" border=\"1\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Tweets</th>\n",
    "      <th>Date</th>\n",
    "      <th>Without Stop Words</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>@BongaDlulane Please send an email to mediades...</td>\n",
    "      <td>2019-11-29 12:50:54</td>\n",
    "      <td>[@bongadlulane, send, email, mediadesk@eskom.c...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n",
    "      <td>2019-11-29 12:46:53</td>\n",
    "      <td>[@saucy_mamiie, pls, log, 0860037566]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>@BongaDlulane Query escalated to media desk.</td>\n",
    "      <td>2019-11-29 12:46:10</td>\n",
    "      <td>[@bongadlulane, query, escalated, media, desk.]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>Before leaving the office this afternoon, head...</td>\n",
    "      <td>2019-11-29 12:33:36</td>\n",
    "      <td>[leaving, office, afternoon,, heading, weekend...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n",
    "      <td>2019-11-29 12:17:43</td>\n",
    "      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>195</th>\n",
    "      <td>Eskom's Visitors Centresâ€™ facilities include i...</td>\n",
    "      <td>2019-11-20 10:29:07</td>\n",
    "      <td>[eskom's, visitors, centresâ€™, facilities, incl...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>196</th>\n",
    "      <td>#Eskom connected 400 houses and in the process...</td>\n",
    "      <td>2019-11-20 10:25:20</td>\n",
    "      <td>[#eskom, connected, 400, houses, process, conn...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>197</th>\n",
    "      <td>@ArthurGodbeer Is the power restored as yet?</td>\n",
    "      <td>2019-11-20 10:07:59</td>\n",
    "      <td>[@arthurgodbeer, power, restored, yet?]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>198</th>\n",
    "      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n",
    "      <td>2019-11-20 10:07:41</td>\n",
    "      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>199</th>\n",
    "      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n",
    "      <td>2019-11-20 10:00:09</td>\n",
    "      <td>[rt, @gp_dhs:, @gautengprovince, commitment, e...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9od8CQ8wUivu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "analyse_predict_student_version-1529 (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
<<<<<<< HEAD
}
>>>>>>> upstream/master
=======
}
>>>>>>> upstream/master
