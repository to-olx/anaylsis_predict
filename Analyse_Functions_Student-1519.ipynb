{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyse_Functions_Student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "91yHydRjEmqq"
      },
      "source": [
        "# Analyse : Predict\n",
        "\n",
        "Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions you will write all use Eskom data/variables.\n",
        "\n",
        "For the predict, you will need to write 7 functions. These functions are:\n",
        "\n",
        "1. Metric Dictionary\n",
        "2. Five Number Summary Dictionary\n",
        "3. Date Parser\n",
        "4. Hashtag & Municipality Remover\n",
        "5. Number of Tweets per Day\n",
        "6. Word Splitter\n",
        "7. Stopwords & Link Remover\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/electrification_by_province.csv'\n",
        "ebp = pd.read_csv(url)\n",
        "\n",
        "for col, row in ebp.iloc[:,1:].iteritems():\n",
        "    ebp[col] = ebp[col].str.replace(',','').astype(int)\n",
        "\n",
        "limpopo = ebp['Limpopo'].to_list()\n",
        "limpopo = [float(x) for x in limpopo]\n",
        "\n",
        "mpumalanga = ebp['Mpumalanga'].to_list()\n",
        "mpumalanga = [float(x) for x in mpumalanga]\n",
        "\n",
        "north_west = ebp['North west'].to_list()\n",
        "north_west = [float(x) for x in north_west]\n",
        "\n",
        "free_state = ebp['Free State'].to_list()\n",
        "free_state = [float(x) for x in free_state]\n",
        "\n",
        "kwazulu_natal = ebp['Kwazulu Natal'].to_list()\n",
        "kwazulu_natal = [float(x) for x in kwazulu_natal]\n",
        "\n",
        "eastern_cape = ebp['Eastern Cape'].to_list()\n",
        "eastern_cape = [float(x) for x in eastern_cape]\n",
        "\n",
        "western_cape = ebp['Western Cape'].to_list()\n",
        "western_cape = [float(x) for x in western_cape]\n",
        "\n",
        "northern_cape = ebp['Northern Cape'].to_list()\n",
        "northern_cape = [float(x) for x in northern_cape]\n",
        "\n",
        "gauteng = ebp['Gauteng'].to_list()\n",
        "gauteng = [float(x) for x in gauteng]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/twitter_nov_2019.csv'\n",
        "twitter_df = pd.read_csv(url)\n",
        "\n",
        "dates = twitter_df['Date'].to_list()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fQL8b34-HThO"
      },
      "source": [
        "# Function 1: Metric Dictionary\n",
        "\n",
        "Write a function which takes in a list of integers and returns a dictionary of the mean, median, variance, standard deviation, min and max. Answers should be rounded to the second decimal.\n",
        "\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "gauteng = [39660.0,\n",
        "            36024.0,\n",
        "            32127.0,\n",
        "            39488.0,\n",
        "            18422.0,\n",
        "            23532.0,\n",
        "            8842.0,\n",
        "            37416.0,\n",
        "            16156.0,\n",
        "            18730.0,\n",
        "            19261.0,\n",
        "            25275.0]\n",
        "\n",
        "dictionary_of_metrics(gauteng) == {'mean': 26244.42,\n",
        "                                   'median': 24403.5,\n",
        "                                   'variance': 108160153.17,\n",
        "                                   'standard deviation': 10400.01,\n",
        "                                   'min': 8842.0,\n",
        "                                   'max': 39660.0}\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dictionary_of_metrics' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-f9d286e890d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m dictionary_of_metrics(gauteng) == {'mean': mean,\n\u001b[0m\u001b[0;32m     40\u001b[0m                                    \u001b[1;34m'median'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmedian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                                    \u001b[1;34m'var'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dictionary_of_metrics' is not defined"
          ]
        }
      ],
      "source": [
        "#Mean\n",
        "\n",
        "mean = sum(gauteng)/len(gauteng)\n",
        "\n",
        "\n",
        "#Median\n",
        "\n",
        "new_gauteng = sorted(gauteng)\n",
        "\n",
        "\n",
        "def median(new_gauteng):\n",
        "    n = int(len(new_gauteng)) #n/2 for odd number #Type error: list indices must be intergers or slices, not floats\n",
        "    \n",
        "    if int(len(new_gauteng) % 2) == 0:\n",
        "        return new_gauteng[int(((n/2) + ((n+1)/2)) / 2)]\n",
        "    else:\n",
        "        return new_gauteng[int((n+1)/2)]\n",
        "\n",
        "\n",
        "#Maximum\n",
        "maximum = sorted(gauteng)[-1]\n",
        "\n",
        "\n",
        "#Minimum\n",
        "minimum = sorted(gauteng)[0]\n",
        "\n",
        "\n",
        "#STD\n",
        "def std_dev(gauteng):\n",
        "  return pstdev(gauteng)\n",
        "\n",
        "\n",
        "#variance\n",
        "\n",
        "def var(gauteng):\n",
        "  return variance(gauteng)\n",
        "\n",
        "\n",
        "dictionary_of_metrics(gauteng) == {'mean': mean,\n",
        "                                   'median': median,\n",
        "                                   'var': var,\n",
        "                                   'std': std,\n",
        "                                   'min': minimun,\n",
        "                                   'max': maximum}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rQIz0kjeJYYi"
      },
      "source": [
        "# Function 2: Five Number Summary\n",
        "\n",
        "Write a function which takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/) Answers should be rounded to the nearest second decimal.\n",
        "\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "gauteng = [39660.0,\n",
        "            36024.0,\n",
        "            32127.0,\n",
        "            39488.0,\n",
        "            18422.0,\n",
        "            23532.0,\n",
        "            8842.0,\n",
        "            37416.0,\n",
        "            16156.0,\n",
        "            18730.0,\n",
        "            19261.0,\n",
        "            25275.0]\n",
        "\n",
        "five_num_summ(gauteng) == {'max': 39660.0,\n",
        "                           'median': 24403.5,\n",
        "                           'min': 8842.0,\n",
        "                           'q1': 18422.5,\n",
        "                           'q3': 36024.5}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def five_num_summ(items):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ETAOSB2oP9-Z"
      },
      "source": [
        "# Function 3: Date Parser\n",
        "\n",
        "Write a function which takes a list of datetime strings and converts it into a list of strings with only the date. \n",
        "<br>\n",
        "<br>\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "dates = ['2019-11-29 12:50:54',\n",
        "         '2019-11-29 12:46:53',\n",
        "         '2019-11-29 12:46:10',\n",
        "         '2019-11-29 12:33:36',\n",
        "         '2019-11-29 12:17:43',\n",
        "         '2019-11-29 11:28:40']\n",
        "\n",
        "date_parser(dates) == ['2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29',\n",
        "                       '2019-11-29']\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def date_parser(dates):\n",
        "    new_format = []\n",
        "\n",
        "    for i in dates:\n",
        "        x = i.split(' ')\n",
        "        new_format.append(x[0])\n",
        "\n",
        "\n",
        "    return new_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W2GhFqo4SvD2"
      },
      "source": [
        "# Function 4: Municipality & Hashtag Remover\n",
        "\n",
        "Write a function which takes in a pandas dataframe and returns the same dataframe which is modified. The function should do the following:\n",
        "\n",
        "* Extract the municipality from a tweet using the dictonary given below into a new column in the same dataframe.\n",
        "* Extract the hashtag from a tweet into a new column in the same data frame.\n",
        "* The column headers should be \"municipality\" & \"hashtags\" respectively.\n",
        "* For those tweets which don't have the either a municipality nor a hashtag, fill it with ```np.nan```.\n",
        "\n",
        "Note: Only pandas and numpy packages may be used.\n",
        "\n",
        "```python\n",
        "\n",
        "municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
        "            '@CityPowerJhb' : 'Johannesburg',\n",
        "            '@eThekwiniM' : 'eThekwini' ,\n",
        "            '@EMMInfo' : 'Ekurhuleni',\n",
        "            '@centlecutility' : 'Mangaung',\n",
        "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
        "            '@CityTshwane' : 'Tshwane'}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ErK3jHb5W8dE"
      },
      "source": [
        "_**Expected Outputs:**_ \n",
        "\n",
        "```python\n",
        "\n",
        "extract_municipality_hashtags(twitter_df).iloc[:11, :10]\n",
        "\n",
        "```\n",
        "![image](https://github.com/RidhaMoosa/eskom_data-/blob/master/function4.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_municipality_hashtags(df):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uSuzSIc7_VUh"
      },
      "source": [
        "# Function 5: Number of Tweets per Day\n",
        "\n",
        "Write a function which calculates the number of tweets that were posted per day. \n",
        "\n",
        "This function should take in a pandas dataframe and return a new dataframe with columns \"```Date```\" & \"```Number of Tweets```\"\n",
        "\n",
        "Note: Only pandas and numpy may be used.\n",
        "\n",
        "_**Expected Output:**_\n",
        "\n",
        "```python\n",
        "\n",
        "number_of_tweets_per_day(twitter_df)\n",
        "\n",
        "```\n",
        "\n",
        "![function5](https://github.com/RidhaMoosa/eskom_data-/blob/master/function5.png?raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def number_of_tweets_per_day(df):\n",
        "\n",
        "  ### Code Here\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Wye_CrLFSgS"
      },
      "source": [
        "# Function 6: Word Splitter\n",
        "\n",
        "Write a function which splits a sentence into a list of the separate words. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n",
        "\n",
        "The function should take in a dataframe and return a data with a new column \"```Split Tweets```\". Words should also all be lowercase.\n",
        "\n",
        "Note: Only pandas and numpy packages may be used.\n",
        "<br>\n",
        "<br>\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "\n",
        "word_spliter(twitter_df) \n",
        "\n",
        "```\n",
        "\n",
        "![Function6](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function6.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word_spliter(df):\n",
        "  \n",
        "  df['Split_Tweets'] =  df['Tweets'].apply(lambda tweet: tweet.lower().split())\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Date</th>\n      <th>Split_Tweets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>@BongaDlulane Please send an email to mediades...</td>\n      <td>2019-11-29 12:50:54</td>\n      <td>[@bongadlulane, please, send, an, email, to, m...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n      <td>2019-11-29 12:46:53</td>\n      <td>[@saucy_mamiie, pls, log, a, call, on, 0860037...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>@BongaDlulane Query escalated to media desk.</td>\n      <td>2019-11-29 12:46:10</td>\n      <td>[@bongadlulane, query, escalated, to, media, d...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Before leaving the office this afternoon, head...</td>\n      <td>2019-11-29 12:33:36</td>\n      <td>[before, leaving, the, office, this, afternoon...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n      <td>2019-11-29 12:17:43</td>\n      <td>[#eskomfreestate, #mediastatement, :, eskom, s...</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>Eskom's Visitors Centres’ facilities include i...</td>\n      <td>2019-11-20 10:29:07</td>\n      <td>[eskom's, visitors, centres’, facilities, incl...</td>\n    </tr>\n    <tr>\n      <td>196</td>\n      <td>#Eskom connected 400 houses and in the process...</td>\n      <td>2019-11-20 10:25:20</td>\n      <td>[#eskom, connected, 400, houses, and, in, the,...</td>\n    </tr>\n    <tr>\n      <td>197</td>\n      <td>@ArthurGodbeer Is the power restored as yet?</td>\n      <td>2019-11-20 10:07:59</td>\n      <td>[@arthurgodbeer, is, the, power, restored, as,...</td>\n    </tr>\n    <tr>\n      <td>198</td>\n      <td>@MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...</td>\n      <td>2019-11-20 10:07:41</td>\n      <td>[@muthambipaulina, @sabcnewsonline, @iol, @enc...</td>\n    </tr>\n    <tr>\n      <td>199</td>\n      <td>RT @GP_DHS: The @GautengProvince made a commit...</td>\n      <td>2019-11-20 10:00:09</td>\n      <td>[rt, @gp_dhs:, the, @gautengprovince, made, a,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>",
            "text/plain": "                                                Tweets                 Date  \\\n0    @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54   \n1           @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53   \n2         @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10   \n3    Before leaving the office this afternoon, head...  2019-11-29 12:33:36   \n4    #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43   \n..                                                 ...                  ...   \n195  Eskom's Visitors Centres’ facilities include i...  2019-11-20 10:29:07   \n196  #Eskom connected 400 houses and in the process...  2019-11-20 10:25:20   \n197       @ArthurGodbeer Is the power restored as yet?  2019-11-20 10:07:59   \n198  @MuthambiPaulina @SABCNewsOnline @IOL @eNCA @e...  2019-11-20 10:07:41   \n199  RT @GP_DHS: The @GautengProvince made a commit...  2019-11-20 10:00:09   \n\n                                          Split_Tweets  \n0    [@bongadlulane, please, send, an, email, to, m...  \n1    [@saucy_mamiie, pls, log, a, call, on, 0860037...  \n2    [@bongadlulane, query, escalated, to, media, d...  \n3    [before, leaving, the, office, this, afternoon...  \n4    [#eskomfreestate, #mediastatement, :, eskom, s...  \n..                                                 ...  \n195  [eskom's, visitors, centres’, facilities, incl...  \n196  [#eskom, connected, 400, houses, and, in, the,...  \n197  [@arthurgodbeer, is, the, power, restored, as,...  \n198  [@muthambipaulina, @sabcnewsonline, @iol, @enc...  \n199  [rt, @gp_dhs:, the, @gautengprovince, made, a,...  \n\n[200 rows x 3 columns]"
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_spliter(twitter_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BsCMKM0KKRsb"
      },
      "source": [
        "# Function 7: Stop Words & Link Remover\n",
        "\n",
        "Write a function which removes the stop words and the ur link from a tweet. The function should follow the criteria below:\n",
        "\n",
        "* Should remove stop words based on the dictionary provided below.\n",
        "* Should remove url's from the tweets. \n",
        "* The function will also need to tokenise thee sentence as indicated in function 6. Note: Function 6 may not be called within this function.\n",
        "* The column should be labelled as \"```Without Stop Words```\"\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "```python \n",
        "stop_words_dict = {'stopwords':['where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', 'may', 'why', '’s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', 'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', 'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', 'their', 'various', 'thereafter', '‘d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', 'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', 'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', '’ve', 'might', 'see', 'whose', 'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', 'became', 'however', 'many', 'thence', 'onto', '‘m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', 'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', 'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', 'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', 'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', 'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', '’d', 'under', 'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', 'n’t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', 'much', 'another', 'since', 'hundred', 'serious', '‘ve', 'ever', 'out', 'full', 'themselves', 'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', 'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', '’ll', 'latterly', 'are', 'ten', 'hers', 'should', 'they', '‘s', 'either', 'am', 'be', 'perhaps', '’re', 'only', 'namely', 'sixty', 'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', 'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', '‘ll', 'too', 'seems', '’m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', 'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', 'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', 'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'n‘t', 'him', 'could', 'front', 'within', '‘re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', 'same', 'were', 'it', 'every', 'third', 'together']}\n",
        "```\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "_**Expected Output**_:\n",
        "\n",
        "```python\n",
        "stop_words_http_remover(twitter_df)\n",
        "```\n",
        "\n",
        "![function7](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function7.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stop_words_http_remover(df):\n",
        "\n",
        "  # Code Here\n",
        "\n",
        "  pass"
      ]
    }
  ]
}